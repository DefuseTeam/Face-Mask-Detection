{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "O1iGVKieeNnj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "from os import getcwd\n",
    "from os import listdir\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import imutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image  as mpimg\n",
    "import pickle\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "G5B9MnMyvgGA"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "r24qH53YvtqV"
   },
   "outputs": [],
   "source": [
    "TRAINING_DIR = \"dataset/train\"\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "I_guGMopwJ_Q",
    "outputId": "aaa68cc6-5503-4e29-b9a5-f08f0a7086f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1118 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR, \n",
    "                                                    batch_size=10, \n",
    "                                                    target_size=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "TskXaHfhy4bU",
    "outputId": "d3f6eeab-80c7-4e91-83c4-9a779637957b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 258 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_DIR = \"dataset/validation\"\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR, \n",
    "                                                         batch_size=10, \n",
    "                                                         target_size=(150, 150))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hnA4Hb3awaed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91845\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(100, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(100, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0UFKkNSNwxO_",
    "outputId": "cb7ad469-18a5-40ab-8ba3-3ef514980118"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From C:\\Users\\91845\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.5520 - acc: 0.7554Epoch 1/30\n",
      "112/112 [==============================] - 62s 557ms/step - loss: 0.5525 - acc: 0.7549 - val_loss: 0.2233 - val_acc: 0.9535\n",
      "Epoch 2/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3079 - acc: 0.8836Epoch 1/30\n",
      "112/112 [==============================] - 62s 558ms/step - loss: 0.3066 - acc: 0.8837 - val_loss: 0.0985 - val_acc: 0.9767\n",
      "Epoch 3/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.2783 - acc: 0.8908Epoch 1/30\n",
      "112/112 [==============================] - 62s 553ms/step - loss: 0.2783 - acc: 0.8909 - val_loss: 0.0950 - val_acc: 0.9612\n",
      "Epoch 4/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.2291 - acc: 0.9125Epoch 1/30\n",
      "112/112 [==============================] - 62s 551ms/step - loss: 0.2292 - acc: 0.9123 - val_loss: 0.1108 - val_acc: 0.9496\n",
      "Epoch 5/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1965 - acc: 0.9269Epoch 1/30\n",
      "112/112 [==============================] - 62s 550ms/step - loss: 0.1962 - acc: 0.9275 - val_loss: 0.1062 - val_acc: 0.9729\n",
      "Epoch 6/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.2299 - acc: 0.9106Epoch 1/30\n",
      "112/112 [==============================] - 62s 552ms/step - loss: 0.2319 - acc: 0.9106 - val_loss: 0.1581 - val_acc: 0.9457\n",
      "Epoch 7/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.2299 - acc: 0.9161Epoch 1/30\n",
      "112/112 [==============================] - 62s 552ms/step - loss: 0.2292 - acc: 0.9159 - val_loss: 0.0721 - val_acc: 0.9729\n",
      "Epoch 8/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.2262 - acc: 0.9197Epoch 1/30\n",
      "112/112 [==============================] - 62s 556ms/step - loss: 0.2258 - acc: 0.9195 - val_loss: 0.0869 - val_acc: 0.9690\n",
      "Epoch 9/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.2656 - acc: 0.9052Epoch 1/30\n",
      "112/112 [==============================] - 64s 568ms/step - loss: 0.2644 - acc: 0.9061 - val_loss: 0.0786 - val_acc: 0.9729\n",
      "Epoch 10/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1605 - acc: 0.9449Epoch 1/30\n",
      "112/112 [==============================] - 63s 565ms/step - loss: 0.1592 - acc: 0.9454 - val_loss: 0.0576 - val_acc: 0.9767\n",
      "Epoch 11/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1444 - acc: 0.9404Epoch 1/30\n",
      "112/112 [==============================] - 61s 549ms/step - loss: 0.1441 - acc: 0.9401 - val_loss: 0.0449 - val_acc: 0.9806\n",
      "Epoch 12/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1732 - acc: 0.9413Epoch 1/30\n",
      "112/112 [==============================] - 60s 539ms/step - loss: 0.1722 - acc: 0.9419 - val_loss: 0.0448 - val_acc: 0.9922\n",
      "Epoch 13/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1627 - acc: 0.9386Epoch 1/30\n",
      "112/112 [==============================] - 61s 543ms/step - loss: 0.1618 - acc: 0.9392 - val_loss: 0.0472 - val_acc: 0.9845\n",
      "Epoch 14/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9540Epoch 1/30\n",
      "112/112 [==============================] - 61s 540ms/step - loss: 0.1344 - acc: 0.9544 - val_loss: 0.0382 - val_acc: 0.9806\n",
      "Epoch 15/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1546 - acc: 0.9477Epoch 1/30\n",
      "112/112 [==============================] - 60s 538ms/step - loss: 0.1535 - acc: 0.9481 - val_loss: 0.0424 - val_acc: 0.9884\n",
      "Epoch 16/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1427 - acc: 0.9495Epoch 1/30\n",
      "112/112 [==============================] - 60s 539ms/step - loss: 0.1422 - acc: 0.9490 - val_loss: 0.0288 - val_acc: 0.9961\n",
      "Epoch 17/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9567Epoch 1/30\n",
      "112/112 [==============================] - 61s 541ms/step - loss: 0.1172 - acc: 0.9571 - val_loss: 0.0925 - val_acc: 0.9651\n",
      "Epoch 18/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.2134 - acc: 0.9287Epoch 1/30\n",
      "112/112 [==============================] - 61s 543ms/step - loss: 0.2127 - acc: 0.9284 - val_loss: 0.2018 - val_acc: 0.9302\n",
      "Epoch 19/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1769 - acc: 0.9431Epoch 1/30\n",
      "112/112 [==============================] - 60s 539ms/step - loss: 0.1766 - acc: 0.9436 - val_loss: 0.0411 - val_acc: 0.9961\n",
      "Epoch 20/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1711 - acc: 0.9368Epoch 1/30\n",
      "112/112 [==============================] - 66s 587ms/step - loss: 0.1700 - acc: 0.9374 - val_loss: 0.0616 - val_acc: 0.9729\n",
      "Epoch 21/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9675Epoch 1/30\n",
      "112/112 [==============================] - 63s 563ms/step - loss: 0.0931 - acc: 0.9678 - val_loss: 0.0202 - val_acc: 0.9922\n",
      "Epoch 22/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1362 - acc: 0.9477Epoch 1/30\n",
      "112/112 [==============================] - 61s 547ms/step - loss: 0.1367 - acc: 0.9472 - val_loss: 0.0333 - val_acc: 0.9806\n",
      "Epoch 23/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.0856 - acc: 0.9720Epoch 1/30\n",
      "112/112 [==============================] - 63s 563ms/step - loss: 0.0849 - acc: 0.9723 - val_loss: 0.0201 - val_acc: 0.9922\n",
      "Epoch 24/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.0992 - acc: 0.9621Epoch 1/30\n",
      "112/112 [==============================] - 67s 597ms/step - loss: 0.0997 - acc: 0.9615 - val_loss: 0.0324 - val_acc: 0.9961\n",
      "Epoch 25/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1508 - acc: 0.9531Epoch 1/30\n",
      "112/112 [==============================] - 66s 593ms/step - loss: 0.1520 - acc: 0.9526 - val_loss: 0.1282 - val_acc: 0.9884\n",
      "Epoch 26/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1751 - acc: 0.9431Epoch 1/30\n",
      "112/112 [==============================] - 65s 583ms/step - loss: 0.1756 - acc: 0.9428 - val_loss: 0.1054 - val_acc: 0.9690\n",
      "Epoch 27/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1709 - acc: 0.9449Epoch 1/30\n",
      "112/112 [==============================] - 66s 587ms/step - loss: 0.1700 - acc: 0.9454 - val_loss: 0.0710 - val_acc: 0.9922\n",
      "Epoch 28/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1682 - acc: 0.9504Epoch 1/30\n",
      "112/112 [==============================] - 67s 597ms/step - loss: 0.1672 - acc: 0.9508 - val_loss: 0.0611 - val_acc: 0.9690\n",
      "Epoch 29/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1297 - acc: 0.9522Epoch 1/30\n",
      "112/112 [==============================] - 65s 580ms/step - loss: 0.1294 - acc: 0.9526 - val_loss: 0.0388 - val_acc: 0.9884\n",
      "Epoch 30/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9639Epoch 1/30\n",
      "112/112 [==============================] - 66s 590ms/step - loss: 0.1187 - acc: 0.9642 - val_loss: 0.0352 - val_acc: 0.9922\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't pickle _thread._local objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5542e0f192df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                    )\n\u001b[0;32m      5\u001b[0m \u001b[0msave_classifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cnn.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_classifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0msave_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't pickle _thread._local objects"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator ,\n",
    "                              epochs=30,\n",
    "                              validation_data=validation_generator\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91845\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\91845\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "new_model=keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "nQq_OVseqwGp"
   },
   "outputs": [],
   "source": [
    "face_clsfr=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "SucxddsPhOmj"
   },
   "outputs": [],
   "source": [
    "labels_dict={0:'without_mask',1:'with_mask'}\n",
    "color_dict={0:(0,0,255),1:(0,255,0)}\n",
    "\n",
    "size = 4\n",
    "webcam = cv2.VideoCapture(0) #Use camera 0\n",
    "\n",
    "# We load the xml file\n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "while True:\n",
    "    (rval, im) = webcam.read()\n",
    "    im=cv2.flip(im,1,1) #Flip to act as a mirror\n",
    "\n",
    "    # Resize the image to speed up detection\n",
    "    mini = cv2.resize(im, (im.shape[1] // size, im.shape[0] // size))\n",
    "\n",
    "    # detect MultiScale / faces \n",
    "    faces = classifier.detectMultiScale(mini)\n",
    "\n",
    "    # Draw rectangles around each face\n",
    "    for f in faces:\n",
    "        (x, y, w, h) = [v * size for v in f] #Scale the shapesize backup\n",
    "        #Save just the rectangle faces in SubRecFaces\n",
    "        face_img = im[y:y+h, x:x+w]\n",
    "        resized=cv2.resize(face_img,(150,150))\n",
    "        normalized=resized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,150,150,3))\n",
    "        reshaped = np.vstack([reshaped])\n",
    "        result=new_model.predict(reshaped)\n",
    "        #print(result)\n",
    "        \n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "      \n",
    "        cv2.rectangle(im,(x,y),(x+w,y+h),color_dict[label],2)\n",
    "        cv2.rectangle(im,(x,y-40),(x+w,y),color_dict[label],-1)\n",
    "        cv2.putText(im, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "        \n",
    "    # Show the image\n",
    "    cv2.imshow('LIVE',   im)\n",
    "    key = cv2.waitKey(10)\n",
    "    # if Esc key is press then break out of the loop \n",
    "    if key == 27: #The Esc key\n",
    "        break\n",
    "# Stop video\n",
    "webcam.release()\n",
    "\n",
    "# Close all started windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "final_mask.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
